{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rule Mining Python Hands-on : Market Basket Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fmarciaturner%2Ffiles%2F2018%2F01%2FWegmans-Produce-1.jpg\" width=\"800px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a detailed explaination about what is <b>Market Basket Analysis</b>.Market basket analysis is generally done by the retailers to check the combination of two or more items that the customers are likely to buy. So let's see what is Market Basket and what does its analysis mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:12.344473Z",
     "start_time": "2022-02-20T07:33:11.205407Z"
    }
   },
   "outputs": [],
   "source": [
    "#Data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Visualizations\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "import squarify\n",
    "import matplotlib\n",
    "\n",
    "#for market basket analysis (using apriori)\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "#for preprocessing\n",
    "from mlxtend.preprocessing import TransactionEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:12.486499Z",
     "start_time": "2022-02-20T07:33:12.349457Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load market data here\n",
    "data = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:12.502451Z",
     "start_time": "2022-02-20T07:33:12.491411Z"
    }
   },
   "outputs": [],
   "source": [
    "#shape\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:12.550407Z",
     "start_time": "2022-02-20T07:33:12.506409Z"
    }
   },
   "outputs": [],
   "source": [
    "#one row is items purchased in a single transaction, for each item recorded in single column\n",
    "#head of data\n",
    "data.head()\n",
    "\n",
    "#tail of data\n",
    "data.tail()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can find that data needs a lot of preprocessing.So let's preprocess the data.We use the TransactionEncoder() of mlxtend.preprocessing to do this work for us. The TransactionEncoder() is an Encoder class for transaction data in Python list.It finds out what are all the different products in the transactions and will assign each transaction a list which contains a boolean array where each index represnts the corresponding product whether purchased in the transaction or not i.e. True or False.\n",
    "\n",
    "It needs input as a python list of lists, where the outer list stores the n transactions and the inner list stores the items.\n",
    "\n",
    "It returns the one-hot encoded boolean array of the input transactions, where the columns represent the unique items found in the input array in alphabetic order. \n",
    "For further details you can refer its documentation: <br><a href=\"http://rasbt.github.io/mlxtend/user_guide/preprocessing/TransactionEncoder/\">TransactionEncoder</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.138410Z",
     "start_time": "2022-02-20T07:33:12.552406Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Converting into required format of TransactionEncoder()\n",
    "transactions=[]\n",
    "for i in range(0,len(data)):\n",
    "    transactions.append([str(data.values[i,j]) for j in range(0,len(data.columns))])\n",
    "\n",
    "transactions=np.array(transactions)\n",
    "\n",
    "transactions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the MLxtend package for Transaction encoder. <br>\n",
    "\n",
    "Apriori is a popular algorithm for extracting frequent itemsets with applications in association rule learning. <br>\n",
    "An itemset = <i>\"frequent itemset\"</i> if it meets a user-specificed support threshold. <br>\n",
    "We will need to preprocess the dataframe into a one-hot encoded dataframe.\n",
    "[refer Example 1](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.311554Z",
     "start_time": "2022-02-20T07:33:13.140408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the transaction encoder function from mlxtend\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "# Instantiate transaction encoder and identify unique items\n",
    "encoder = \n",
    "\n",
    "# One-hot encode transactions\n",
    "onehot = \n",
    "\n",
    "# Convert one-hot encoded data to DataFrame, remove the nan.\n",
    "data = pd.DataFrame(onehot, columns = encoder.columns_,dtype=int).drop('nan', axis=1)\n",
    "\n",
    "# Print the one-hot encoded transaction dataset\n",
    "data.shape\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Lets do some Data Visualizations...\n",
    "\n",
    "\n",
    "### Data Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.646515Z",
     "start_time": "2022-02-20T07:33:13.313517Z"
    }
   },
   "outputs": [],
   "source": [
    "#Visualise the Top 20 items purchased frequently\n",
    "\n",
    "r=data.sum(axis=0).sort_values(ascending=False)[:20]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find that mineral water is the most purchased item from the store, we may advice that mineral water must be always in the stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.884262Z",
     "start_time": "2022-02-20T07:33:13.648479Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a color palette, mapped to these values\n",
    "my_values=r.values\n",
    "cmap = matplotlib.cm.Blues\n",
    "mini=min(my_values)\n",
    "maxi=max(my_values)\n",
    "norm = matplotlib.colors.Normalize(vmin=mini, vmax=maxi)\n",
    "colors = [cmap(norm(value)) for value in my_values]\n",
    "\n",
    "#treemap of top 20 frequent items\n",
    "plt.figure(figsize=(10,10))\n",
    "squarify.plot(sizes=r.values, label=r.index, alpha=.7,color=colors)\n",
    "plt.title(\"Tree map of top 20 items\")\n",
    "plt.axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now work on apriori to find frequent itemsets.\n",
    "\n",
    "Refer to [Example 2](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/#example-2-selecting-and-filtering-results) - using Apriori to create frequent itemsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.931855Z",
     "start_time": "2022-02-20T07:33:13.885241Z"
    }
   },
   "outputs": [],
   "source": [
    "#let us return itemsets with at least 5% support:\n",
    "freq_items="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.947866Z",
     "start_time": "2022-02-20T07:33:13.932873Z"
    }
   },
   "outputs": [],
   "source": [
    "freq_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tell us that there are 27 frequent itemsets of different lengths , so the first step of our apriori algorithm is finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.963428Z",
     "start_time": "2022-02-20T07:33:13.949866Z"
    }
   },
   "outputs": [],
   "source": [
    "#Now let's generate association rules with lift > 1.3\n",
    "res= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:13.978730Z",
     "start_time": "2022-02-20T07:33:13.964712Z"
    }
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see the 4 rules generated with lift greater than 1.3\n",
    "\n",
    "Intuition we can get from confidence is that:<pre>\n",
    "    32% of transactions containing chocolate also contain mineral water\n",
    "    22% of transactions containing mineral water also contain chocolate\n",
    "    34% of transactions containing spaghetti also contain mineral water\n",
    "    25% of transactions containing mineral water also contain spaghetti\n",
    "</pre>\n",
    "\n",
    "\n",
    "There is more chance of the transaction {spaghetti,mineral water} than {chocolate,mineral water} as we can find the interesting nature of rule by comparing lift,leverage and conviction of {spaghetti,mineral water} and {chocolate,mineral water}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rule is said to be interesting if it is unexpected(suprising to user) and/or actionable(user can do something with it).It's a subjective measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting and Filtering the Itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.026758Z",
     "start_time": "2022-02-20T07:33:13.980722Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate frequent itemsets with 5% support.\n",
    "frequent_itemsets = \n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.058755Z",
     "start_time": "2022-02-20T07:33:14.028757Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter the item sets with length = 2 and support more than 10%\n",
    "\n",
    "frequent_itemsets[ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.074723Z",
     "start_time": "2022-02-20T07:33:14.059723Z"
    }
   },
   "outputs": [],
   "source": [
    "# getting th item sets with length = 1 and support more han 10%\n",
    "\n",
    "frequent_itemsets[ ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FP GROWTH(Frequent Pattern Growth)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortcomings Of Apriori Algorithm\n",
    "\n",
    "-Using Apriori needs a generation of candidate itemsets. These itemsets may be large in number if the itemset in the database is huge.\n",
    "\n",
    "\n",
    "-Apriori needs multiple scans of the database to check the support of each itemset generated and this leads to high costs.\n",
    "These shortcomings can be overcome using the FP growth algorithm.\n",
    "\n",
    "[Explanation of FP Growth](https://www.softwaretestinghelp.com/fp-growth-algorithm-data-mining/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.090755Z",
     "start_time": "2022-02-20T07:33:14.075725Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "from mlxtend.frequent_patterns import fpgrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.186758Z",
     "start_time": "2022-02-20T07:33:14.091724Z"
    }
   },
   "outputs": [],
   "source": [
    "#running the fpgrowth algorithm with at least 5% support:\n",
    "res=fpgrowth(data,min_support=0.05,use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.202721Z",
     "start_time": "2022-02-20T07:33:14.187723Z"
    }
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.218870Z",
     "start_time": "2022-02-20T07:33:14.204725Z"
    }
   },
   "outputs": [],
   "source": [
    "res=association_rules(res,metric=\"lift\",min_threshold=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.234891Z",
     "start_time": "2022-02-20T07:33:14.220724Z"
    }
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could observe that {spaghetti}->{mineral water} is mostly like to occur as we can observe it from the lift, which is the same as apriori."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apriori Vs FP Growth\n",
    "\n",
    "Since FP-Growth doesn't require creating candidate sets explicitly, it can be magnitudes faster than the alternative Apriori algorithm. FP-Growth is about 5 times faster.Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:14.855813Z",
     "start_time": "2022-02-20T07:33:14.235738Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "l=[0.01,0.02,0.03,0.04,0.05]\n",
    "t=[]\n",
    "for i in l:\n",
    "    t1=time.time()\n",
    "    apriori(data,min_support=i,use_colnames=True)\n",
    "    t2=time.time()\n",
    "    t.append((t2-t1)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:15.347780Z",
     "start_time": "2022-02-20T07:33:14.864780Z"
    }
   },
   "outputs": [],
   "source": [
    "l=[0.01,0.02,0.03,0.04,0.05]\n",
    "f=[]\n",
    "for i in l:\n",
    "    t1=time.time()\n",
    "    fpgrowth(data,min_support=i,use_colnames=True)\n",
    "    t2=time.time()\n",
    "    f.append((t2-t1)*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-20T07:33:15.602791Z",
     "start_time": "2022-02-20T07:33:15.348721Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=l,y=f,label=\"fpgrowth\")\n",
    "sns.lineplot(x=l,y=t,label=\"apriori\")\n",
    "plt.xlabel(\"Min_support Threshold\")\n",
    "plt.ylabel(\"Run Time in ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can gain the required insights from the above graph about the run time comparision between the apriori and fpgrowth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECLAT ALGORITHM\n",
    "\n",
    "\n",
    "BottleNecks of Apriori:\n",
    "<ul>\n",
    "    <li>Candidate generation can result in huge candidate sets</li>\n",
    "    <li>Multiple Scans of Database--- needs (n+1) scans,n is the longest pattern</li>\n",
    "</ul>\n",
    "\n",
    "To solve some of the above problems,Eclat has been introduced.\n",
    "\n",
    "\n",
    "The ECLAT algorithm stands for **Equivalence Class Clustering and bottom-up Lattice Traversal**. \n",
    "* It is one of the popular methods of Association Rule mining. It is a more efficient and scalable version of the Apriori algorithm. \n",
    "* While the Apriori algorithm works in a horizontal sense imitating the Breadth-First Search of a graph, the ECLAT algorithm works in a **vertical manner** just like the **Depth-First Search** of a graph. This vertical approach of the ECLAT algorithm makes it a faster algorithm than the Apriori algorithm.\n",
    "\n",
    "\n",
    "How it works:\n",
    "\n",
    "The basic idea is to use Transaction Id Sets(tidsets) intersections to compute the support value of a candidate and avoiding the generation of subsets which do not exist in the prefix tree. In the first call of the function, all single items are used along with their tidsets. Then the function is called recursively and in each recursive call, each item-tidset pair is verified and combined with other item-tidset pairs. This process is continued until no candidate item-tidset pairs can be combined\n",
    "\n",
    "\n",
    "Eg:\n",
    "\n",
    "t1={a,b,c}\n",
    "t2={a,b}\n",
    "t3={a}\n",
    "\n",
    "now above is horizontal layout where t1,t2,t3 are transactions a,b,c are products.now let's make it into vertical layout....\n",
    "\n",
    "    k=1,          min_support=0.5\n",
    "    a={t1,t2,t3}, sup=1\n",
    "    b={t1,t2},    sup=0.66\n",
    "    c={t1},       sup=0.33\n",
    "\n",
    "\n",
    "now we eliminate c as is supp<min_support and them generate itemsets of length k=2\n",
    "\n",
    "    k=2,           min_support=0.5\n",
    "    {a,b}={t1,t2}, supp=0.5\n",
    "\n",
    "and we can't generate anymore sets so we end up with only {a,b}.\n",
    "\n",
    "<b>This method has an advantage over Apriori as it does not require scanning the database to find the support of k+1 itemsets. This is because the Transaction set will carry the count of occurrence of each item in the transaction (support). The bottleneck comes when there are many transactions taking huge memory and computational time for intersecting the sets.</b>\n",
    "\n",
    "If you want further reference you can visit : <a href=\"https://www.geeksforgeeks.org/ml-eclat-algorithm/\">Eclat Algo</a>\n",
    "\n",
    "\n",
    "<b>Advantages over Apriori algorithm:-</b>\n",
    "<ul>\n",
    "<li>Memory Requirements: Since the ECLAT algorithm uses a Depth-First Search approach, it uses less memory than Apriori algorithm.</li>\n",
    "    <li>Speed: The ECLAT algorithm is typically faster than the Apriori algorithm.</li>\n",
    "<li>Number of Computations: The ECLAT algorithm does not involve the repeated scanning of the data to compute the individual support values.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "248px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "34b6ff8fdf67aee58fe116336c3c4bcfde7a1d4e61896e945dd0afa6e11146f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
